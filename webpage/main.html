<!DOCTYPE html>
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script
    async
    src="https://www.googletagmanager.com/gtag/js?id=UA-178132094-1"
  ></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag("js", new Date());

    gtag("config", "UA-178132094-1");
  </script>

  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>AdvBench: Adversarial robustness benchmark</title>
  <link
    rel="stylesheet"
    href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"
  />
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script
    id="MathJax-script"
    async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
  ></script>
  <script
    src="https://kit.fontawesome.com/b939870cfb.js"
    crossorigin="anonymous"
  ></script>
  <link
    rel="stylesheet"
    href="https://cdnjs.cloudflare.com/ajax/libs/foundation/6.4.3/css/foundation.min.css"
  />
  <link
    rel="stylesheet"
    href="https://cdn.datatables.net/1.10.21/css/dataTables.foundation.min.css"
  />

  <script
    type="text/javascript"
    src="https://code.jquery.com/jquery-3.5.1.js"
  ></script>
  <script
    type="text/javascript"
    src="https://cdn.datatables.net/1.10.21/js/jquery.dataTables.min.js
    "
  ></script>
  <script
    type="text/javascript"
    src="https://cdn.datatables.net/1.10.21/js/dataTables.foundation.min.js"
  ></script>
  <script>
    $(document).ready(function () {
      $("#leaderboard").DataTable({
        lengthMenu: [15, 25, 50, 75, 100],
      });
    });
    $(document).ready(function () {
      $("#leaderboard2").DataTable({
        lengthMenu: [15, 25, 50, 75, 100],
      });
    });
  </script>

  <link rel="stylesheet" href="./css/main.css" />
</head>

<body>
  <!-- <hr class="majorrule" /> -->
  <nav>
    <ul class="left">
      <li>AdvBench</li>
    </ul>
    <ul class="right">
      <li><a href="#leaderboard">Leaderboard</a></li>
      <li><a href="#leaderboard">Library</a></li>
      <li><a href="#">Analysis</a></li>
    </ul>
  </nav>

  <!-- <hr class="toprule" /> -->

  <header>
    <div class="logo"><img src="./images/logo.png" alt="logo" /></div>
    <div class="title">AdvBench</div>
    <div class="description">A shared benchmark for adversarial robustness</div>
  </header>
  <!-- <hr class="toprule" /> -->

  <!-- <hr class="title-rule" /> -->
  <div class="content">
    <section id="introduction">
      <div class="overview">
        <p>
          The goal of <strong>AdvBench</strong> is to systematically track the
          <em>real</em> progress in adversarial robustness. There are already
          <a
            href="https://nicholas.carlini.com/writing/2019/all-adversarial-example-papers.html"
            >more than 2&#39;000 papers</a
          >
          on this topic, but it is still unclear which approaches
          <em>really</em> work and which only lead to
          <a href="https://arxiv.org/abs/1802.00420">overestimated robustness</a
          >. We start from doing the benchmarking the Linf-robustness since it
          is the most studied setting in the literature. We plan to extend the
          benchmark to other threat models in the future: first to other
          Lp-norms and then to more general perturbation sets.
          <strong>AdvBench</strong> provides two key modules.
        </p>
        <div class="flexbox-container features">
          <div class="element">
            <div class="icon">
              <img
                src="https://img.icons8.com/wired/100/000000/leaderboard.png"
              />
            </div>
            <p>Well-maintained leaderboard</p>
          </div>
          <div class="element">
            <div class="icon">
              <img
                src="https://img.icons8.com/ios-glyphs/80/000000/user-credentials.png"
              />
            </div>
            <p>Unified access to state-of-the-art <br />adversarial defenses</p>
          </div>
        </div>
      </div>
      <div class="details">
        <div class="box usage">
          <p>Usage</p>
          <div class="divider"><hr /></div>
          <div class="codeblock">
            <pre><code></code>from model_zoo.models import model_dicts 
from utils import load_model 
from attacks import AutoAttack 

# create model with robustly trained checkpoints 
model = load_model(model_name='Carmon2019Unlabeled') 

# Adversarial robustness
adversary = AutoAttack(model, norm='Linf', eps=epsilon, plus=False) 
x_adv = adversary.run_standard_evaluation(images, labels)</pre>
          </div>
        </div>
        <div class="box images">
          <p>Analysis</p>
          <div class="divider"><hr /></div>
          Check out the complete report <a href="#">here</a>.
          <div class="scroller analysis-images">
            <img
              src="./images/aa_robustness_vs_clean.png"
              alt="robustness_vs_clean"
            />
            <img
              src="./images/aa_robustness_vs_venues.png"
              alt="robustness_vs_venues"
            />
          </div>
        </div>
      </div>
      <div class="vspace"></div>
    </section>

    <section>
      <div class="heading">
        <p>
          Leaderboard
          <span class="heading-math"
            >\(\left (\|\epsilon\|_{\infty} = 8 \right )\)</span
          >
        </p>
      </div>
      <table id="leaderboard" class="datatable" style="width: 100%">
        <thead>
          <tr>
            <th class="rank">Rank</th>
            <th class="method">Method</th>
            <th class="ca">
              Clean <br />
              accuracy
            </th>
            <th class="aa">
              Adversarial <br />
              accuracy
            </th>
            <th class="extra-data">Extra <br />data</th>
            <th class="arch">Architecture</th>
            <th class="venue">Venue</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td class="ranktd">1</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1905.13736"
                >Unlabeled Data Improves Adversarial Robustness</a
              >
            </td>
            <td class="catd">89.69</td>
            <td class="aatd">59.53</td>
            <td class="datatd">&#9745;</td>
            <td class="archtd">WideResNet-28-10</td>
            <td class="venuetd">NeurIPS 2019</td>
          </tr>
          <tr>
            <td class="ranktd">2</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/2002.10509"
                >HYDRA: Pruning Adversarially Robust Neural Networks</a
              >
            </td>
            <td class="catd">88.98</td>
            <td class="aatd">57.14</td>
            <td class="datatd">&#9745;</td>
            <td class="archtd">WideResNet-28-10</td>
            <td class="venuetd">N/A</td>
          </tr>
          <tr>
            <td class="ranktd">3</td>
            <td class="methoddt">
              <a href="https://openreview.net/forum?id=rklOg6EFwS"
                >Improving Adversarial Robustness Requires Revisiting
                Misclassified Examples</a
              >
            </td>
            <td class="catd">87.50</td>
            <td class="aatd">56.29</td>
            <td class="datatd">&#9745;</td>
            <td class="archtd">WideResNet-28-10</td>
            <td class="venuetd">ICLR 2020</td>
          </tr>
          <tr>
            <td class="ranktd">4</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1905.13725"
                >Are Labels Required for Improving Adversarial Robustness?</a
              >
            </td>
            <td class="catd">86.46</td>
            <td class="aatd">56.03</td>
            <td class="datatd">&#9745;</td>
            <td class="archtd">WideResNet-28-10</td>
            <td class="venuetd">NeurIPS 2019</td>
          </tr>
          <tr>
            <td class="ranktd">5</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1901.09960"
                >Using Pre-Training Can Improve Model Robustness and
                Uncertainty</a
              >
            </td>
            <td class="catd">87.11</td>
            <td class="aatd">54.92</td>
            <td class="datatd">&#9745;</td>
            <td class="archtd">WideResNet-28-10</td>
            <td class="venuetd">ICML 2019</td>
          </tr>
          <tr>
            <td class="ranktd">6</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/2002.08619"
                >Boosting Adversarial Training with Hypersphere Embedding</a
              >
            </td>
            <td class="catd">85.14</td>
            <td class="aatd">53.74</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-34-20</td>
            <td class="venuetd">N/A</td>
          </tr>
          <tr>
            <td class="ranktd">7</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/2002.11569"
                >Overfitting in adversarially robust deep learning</a
              >
            </td>
            <td class="catd">85.34</td>
            <td class="aatd">53.42</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-34-20</td>
            <td class="venuetd">ICML 2020</td>
          </tr>
          <tr>
            <td class="ranktd">8</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/2002.10319"
                >Self-Adaptive Training: beyond Empirical Risk Minimization</a
              >
              <br /><span class="td-footer"
                >Uses \(\|\epsilon\|_{\infty}\) = 7.9 instead of 8.
              </span>
            </td>
            <td class="catd">83.48</td>
            <td class="aatd">53.34</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-34-10</td>
            <td class="venuetd">N/A</td>
          </tr>
          <tr>
            <td class="ranktd">9</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1901.08573"
                >Theoretically Principled Trade-off between Robustness and
                Accuracy</a
              >
              <br /><span class="td-footer"
                >Uses \(\|\epsilon\|_{\infty}\) = 7.9 instead of 8.
              </span>
            </td>
            <td class="catd">84.92</td>
            <td class="aatd">53.08</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-34-10</td>
            <td class="venuetd">ICML 2019</td>
          </tr>
          <tr>
            <td class="ranktd">10</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1907.02610v2"
                >Adversarial Robustness through Local Linearization</a
              >
            </td>
            <td class="catd">86.28</td>
            <td class="aatd">52.84</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-40-8</td>
            <td class="venuetd">NeurIPS 2019</td>
          </tr>
          <tr>
            <td class="ranktd">11</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/2003.12862"
                >Adversarial Robustness: From Self-Supervised Pre-Training to
                Fine-Tuning</a
              >
              <br /><span class="td-footer">Uses ensembles of 3-models</span>
            </td>
            <td class="catd">86.04</td>
            <td class="aatd">51.56</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">ResNet-50</td>
            <td class="venuetd">CVPR 2020</td>
          </tr>
          <tr>
            <td class="ranktd">12</td>
            <td class="methoddt">
              <a href="https://github.com/MadryLab/robustness"
                >Robustness library</a
              >
            </td>
            <td class="catd">87.03</td>
            <td class="aatd">49.25</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">ResNet-50</td>
            <td class="venuetd">N/A</td>
          </tr>
          <tr>
            <td class="ranktd">13</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1905.05186"
                >Harnessing the Vulnerability of Latent Layers in Adversarially
                Trained Models</a
              >
            </td>
            <td class="catd">87.80</td>
            <td class="aatd">49.12</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-34-10</td>
            <td class="venuetd">IJCAI 2019</td>
          </tr>
          <tr>
            <td class="ranktd">14</td>
            <td class="methoddt">
              <a
                href="http://papers.nips.cc/paper/8339-metric-learning-for-adversarial-robustness"
                >Metric Learning for Adversarial Robustness</a
              >
            </td>
            <td class="catd">86.21</td>
            <td class="aatd">47.41</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-34-10</td>
            <td class="venuetd">NeurIPS 2019</td>
          </tr>
          <tr>
            <td class="ranktd">15</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1905.00877"
                >You Only Propagate Once: Accelerating Adversarial Training via
                Maximal Principle</a
              >
            </td>
            <td class="catd">87.20</td>
            <td class="aatd">44.83</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-34-10</td>
            <td class="venuetd">NeurIPS 2019</td>
          </tr>
          <tr>
            <td class="ranktd">16</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1706.06083"
                >Towards Deep Learning Models Resistant to Adversarial
                Attacks</a
              >
            </td>
            <td class="catd">87.14</td>
            <td class="aatd">44.04</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-34-10</td>
            <td class="venuetd">ICLR 2018</td>
          </tr>
          <tr>
            <td class="ranktd">17</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1905.10626"
                >Rethinking Softmax Cross-Entropy Loss for Adversarial
                Robustness</a
              >
            </td>
            <td class="catd">80.89</td>
            <td class="aatd">43.48</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">ResNet-32</td>
            <td class="venuetd">ICLR 2020</td>
          </tr>
          <tr>
            <td class="ranktd">18</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/2001.03994"
                >Fast is better than free: Revisiting adversarial training</a
              >
            </td>
            <td class="catd">83.34</td>
            <td class="aatd">43.21</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">ResNet-18</td>
            <td class="venuetd">ICLR 2020</td>
          </tr>
          <tr>
            <td class="ranktd">19</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1904.12843"
                >Adversarial Training for Free!</a
              >
            </td>
            <td class="catd">86.11</td>
            <td class="aatd">41.47</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-34-10</td>
            <td class="venuetd">NeurIPS 2019</td>
          </tr>
          <tr>
            <td class="ranktd">20</td>
            <td class="methoddt">
              <a href="https://openreview.net/forum?id=HkeryxBtPB"
                >MMA Training: Direct Input Space Margin Maximization through
                Adversarial Training</a
              >
            </td>
            <td class="catd">84.36</td>
            <td class="aatd">41.44</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-28-4</td>
            <td class="venuetd">ICLR 2020</td>
          </tr>
          <tr>
            <td class="ranktd">21</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1905.11911"
                >Controlling Neural Level Sets</a
              >
              <br />
              <span class="td-footer"
                >Uses \(\|\epsilon\|_{\infty}\) = 7.9 instead of 8.
              </span>
            </td>
            <td class="catd">81.30</td>
            <td class="aatd">40.22</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">ResNet-18</td>
            <td class="venuetd">NeurIPS 2019</td>
          </tr>
          <tr>
            <td class="ranktd">22</td>
            <td class="methoddt">
              <a
                href="http://openaccess.thecvf.com/content_CVPR_2019/html/Moosavi-Dezfooli_Robustness_via_Curvature_Regularization_and_Vice_Versa_CVPR_2019_paper"
                >Robustness via Curvature Regularization, and Vice Versa</a
              >
            </td>
            <td class="catd">83.11</td>
            <td class="aatd">38.50</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">ResNet-18</td>
            <td class="venuetd">CVPR 2019</td>
          </tr>
          <tr>
            <td class="ranktd">23</td>
            <td class="methoddt">
              <a
                href="http://papers.nips.cc/paper/8459-defense-against-adversarial-attacks-using-feature-scattering-based-adversarial-training"
                >Defense Against Adversarial Attacks Using Feature
                Scattering-based Adversarial Training</a
              >
            </td>
            <td class="catd">89.98</td>
            <td class="aatd">36.64</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-28-10</td>
            <td class="venuetd">NeurIPS 2019</td>
          </tr>
          <tr>
            <td class="ranktd">24</td>
            <td class="methoddt">
              <a
                href="https://openreview.net/forum?id=Syejj0NYvr&noteId=Syejj0NYvr"
                >Adversarial Interpolation Training: A Simple Approach for
                Improving Model Robustness</a
              >
            </td>
            <td class="catd">90.25</td>
            <td class="aatd">36.45</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-28-10</td>
            <td class="venuetd">N/A</td>
          </tr>
          <tr>
            <td class="ranktd">25</td>
            <td class="methoddt">
              <a
                href="http://openaccess.thecvf.com/content_ICCV_2019/html/Jang_Adversarial_Defense_via_Learning_to_Generate_Diverse_Attacks_ICCV_2019_paper.html"
                >Adversarial Defense via Learning to Generate Diverse Attacks</a
              >
            </td>
            <td class="catd">78.91</td>
            <td class="aatd">34.95</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">ResNet-20</td>
            <td class="venuetd">ICCV 2019</td>
          </tr>
          <tr>
            <td class="ranktd">26</td>
            <td class="methoddt">
              <a href="https://openreview.net/forum?id=rJlf_RVKwr"
                >Sensible adversarial learning</a
              >
            </td>
            <td class="catd">91.51</td>
            <td class="aatd">34.22</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-34-10</td>
            <td class="venuetd">N/A</td>
          </tr>
          <tr>
            <td class="ranktd">27</td>
            <td class="methoddt">
              <a
                href="http://openaccess.thecvf.com/content_ICCV_2019/html/Wang_Bilateral_Adversarial_Training_Towards_Fast_Training_of_More_Robust_Models_ICCV_2019_paper.html"
                >Bilateral Adversarial Training: Towards Fast Training of More
                Robust Models Against Adversarial Attacks</a
              >
            </td>
            <td class="catd">92.80</td>
            <td class="aatd">29.35</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-28-10</td>
            <td class="venuetd">ICCV 2019</td>
          </tr>
          <tr>
            <td class="ranktd">28</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1905.10510"
                >Enhancing Adversarial Defense by k-Winners-Take-All</a
              >
              <br /><span class="td-footer">
                Uses \(\|\epsilon\|_{\infty}\) = 7.9 instead of 8.
              </span>
            </td>
            <td class="catd">79.28</td>
            <td class="aatd">18.50</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">DenseNet-121</td>
            <td class="venuetd">ICLR 2020</td>
          </tr>
          <tr>
            <td class="ranktd">29</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/2003.04286"
                >Manifold Regularization for Adversarial Robustness</a
              >
            </td>
            <td class="catd">90.84</td>
            <td class="aatd">1.35</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">ResNet-18</td>
            <td class="venuetd">N/A</td>
          </tr>
          <tr>
            <td class="ranktd">30</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1904.00887"
                >Adversarial Defense by Restricting the Hidden Space of Deep
                Neural Networks</a
              >
            </td>
            <td class="catd">89.16</td>
            <td class="aatd">0.28</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">ResNet-110</td>
            <td class="venuetd">ICCV 2019</td>
          </tr>
          <tr>
            <td class="ranktd">31</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1912.10185"
                >Jacobian Adversarially Regularized Networks for Robustness</a
              >
            </td>
            <td class="catd">93.79</td>
            <td class="aatd">0.26</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-34-10</td>
            <td class="venuetd">ICLR 2020</td>
          </tr>
          <tr>
            <td class="ranktd">32</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/2006.07682"
                >ClusTR: Clustering Training for Robustness
              </a>
            </td>
            <td class="catd">91.03</td>
            <td class="aatd">0.00</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-28-10</td>
            <td class="venuetd">N/A</td>
          </tr>
          <tr>
            <td class="ranktd">33</td>
            <td class="methoddt"><a href="">Naturally trained model</a></td>
            <td class="catd">94.78</td>
            <td class="aatd">0.0</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-28-10</td>
            <td class="venuetd">N/A</td>
          </tr>
        </tbody>
      </table>
    </section>

    <section>
      <div class="heading">
        <p>
          Leaderboard
          <span class="heading-math"
            >\(\left (\|\epsilon\|_{2} = 0.5 \right )\)</span
          >
        </p>
      </div>
      <table id="leaderboard2" class="datatable" style="width: 100%">
        <thead>
          <tr>
            <th class="rank">Rank</th>
            <th class="method">Method</th>
            <th class="ca">
              Clean <br />
              accuracy
            </th>
            <th class="aa">
              Adversarial <br />
              accuracy
            </th>
            <th class="extra-data">Extra <br />data</th>
            <th class="arch">Architecture</th>
            <th class="venue">Venue</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td class="ranktd">1</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/2003.09461" target="_blank"
                >Adversarial Robustness on In- and Out-Distribution Improves
                Explainability</a
              >
            </td>
            <td class="catd">91.08</td>
            <td class="aatd">72.91</td>
            <td class="datatd">&#9745;</td>
            <td class="archtd">ResNet-50</td>
            <td class="venuetd">ECCV 2020</td>
          </tr>
          <tr>
            <td class="ranktd">2</td>
            <td class="methoddt">
              <a href="https://github.com/MadryLab/robustness" target="_blank"
                >Robustness library</a
              >
            </td>
            <td class="catd">90.83</td>
            <td class="aatd">69.24</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">ResNet-50</td>
            <td class="venuetd">N/A</td>
          </tr>
          <tr>
            <td class="ranktd">3</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/2002.11569" target="_blank"
                >Overfitting in adversarially robust deep learning</a
              >
            </td>
            <td class="catd">88.67</td>
            <td class="aatd">67.68</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">ResNet-18</td>
            <td class="venuetd">ICML 2020</td>
          </tr>
          <tr>
            <td class="ranktd">4</td>
            <td class="methoddt">
              <a href="https://arxiv.org/abs/1811.09600" target="_blank"
                >Decoupling Direction and Norm for Efficient Gradient-Based L2
                Adversarial Attacks and Defenses</a
              >
            </td>
            <td class="catd">89.05</td>
            <td class="aatd">66.44</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-28-10</td>
            <td class="venuetd">CVPR 2019</td>
          </tr>
          <tr>
            <td class="ranktd">5</td>
            <td class="methoddt">
              <a
                href="https://openreview.net/forum?id=HkeryxBtPB"
                target="_blank"
                >MMA Training: Direct Input Space Margin Maximization through
                Adversarial Training</a
              >
            </td>
            <td class="catd">88.02</td>
            <td class="aatd">66.09</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-28-4</td>
            <td class="venuetd">ICLR 2020</td>
          </tr>
          <tr>
            <td class="ranktd">6</td>
            <td class="methoddt">
              <a href="" target="_blank">Naturally trained model</a>
            </td>
            <td class="catd">94.78</td>
            <td class="aatd">0.0</td>
            <td class="datatd">&#9746;</td>
            <td class="archtd">WideResNet-28-10</td>
            <td class="venuetd">N/A</td>
          </tr>
        </tbody>
      </table>
    </section>

    <section id="contributors">
      <div class="heading"><p>Contributions</p></div>
      <hr />
      Some details on welcoming contributions. Quisque id ullamcorper sem. In
      hac habitasse platea dictumst. Suspendisse a semper libero. Nullam a enim
      non nisi ultricies cursus. Quisque eu tincidunt dolor. Fusce non risus eu
      purus tempor auctor. Fusce et placerat turpis. Proin aliquet lorem mi, at
      tempus sapien ornare id. Mauris accumsan, nulla vel posuere sollicitudin,
      nisi massa tristique mauris, eget ullamcorper risus tellus a nibh.
      Curabitur tempus dignissim magna in sagittis.
      <div class="details">
        <div class="box2">
          <p>Submit a new model</p>
          <div class="divider"><hr /></div>
          List steps on submitting a new model.
        </div>
        <div class="box2 usage">
          <p>Maintainers</p>
          <div class="divider"><hr /></div>
          <ul>
            <li>
              <a href="xyz.com" target="_blank">Francesco Croce </a>
              <a href="#"><i class="fas fa-globe"></i></a>
              <a href="#"><i class="fab fa-github"></i></a>
              <a href="#"><i class="ai ai-google-scholar"></i></a>
            </li>
            <li>
              <a href="xyz.com" target="_blank">Maksym Andriushchenko</a>
              <a href="#"><i class="fas fa-globe"></i></a>
              <a href="#"><i class="fab fa-github"></i></a>
              <a href="#"><i class="ai ai-google-scholar"></i></a>
            </li>
            <li>
              <a href="xyz.com" target="_blank">Vikash Sehwag</a>
              <a href="#"><i class="fas fa-globe"></i></a>
              <a href="#"><i class="fab fa-github"></i></a>
              <a href="#"><i class="ai ai-google-scholar"></i></a>
            </li>
          </ul>
        </div>
      </div>
    </section>
  </div>
  <hr />
  <footer>
    <small
      >&copy; 2020, AdvBench;
      <a href="https://icons8.com/icon/100413/access"
        >Access icon by Icons8</a
      ></small
    >
  </footer>
</body>
